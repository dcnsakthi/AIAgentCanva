version: '3.8'

services:
  # Main Streamlit Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    environment:
      - APP_ENV=${APP_ENV:-production}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-demo-mode}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-demo-mode}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY:-demo-mode}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-your-secret-key-change-in-production}
      - GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID:-}
      - GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET:-}
      - MICROSOFT_CLIENT_ID=${MICROSOFT_CLIENT_ID:-}
      - MICROSOFT_CLIENT_SECRET=${MICROSOFT_CLIENT_SECRET:-}
      - MICROSOFT_TENANT_ID=${MICROSOFT_TENANT_ID:-}
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - BACKEND_API_URL=http://backend:8000
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - chromadb
      - redis
      - backend
      - ollama
    volumes:
      - ./projects:/app/projects
      - ./data:/app/data
    networks:
      - ai-agent-network
    restart: unless-stopped

  # Backend API Service
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=sqlite:///./data/agents.db
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - redis
      - chromadb
    volumes:
      - ./data:/app/data
    networks:
      - ai-agent-network
    restart: unless-stopped

  # ChromaDB Vector Database
  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8000:8000"
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}
    volumes:
      - chromadb-data:/chroma/chroma
    networks:
      - ai-agent-network
    restart: unless-stopped

  # Redis Cache and Queue
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - ai-agent-network
    restart: unless-stopped
    command: redis-server --appendonly yes

  # Ollama - Local LLM Service
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - ai-agent-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # For CPU-only, remove the deploy section above

  # Qdrant Vector Database (Alternative)
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - ai-agent-network
    restart: unless-stopped

  # PostgreSQL Database (Optional - for production)
  postgres:
    image: postgres:16-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=aiagents
      - POSTGRES_USER=aiagent
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-changeme}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - ai-agent-network
    restart: unless-stopped

volumes:
  chromadb-data:
  redis-data:
  ollama-data:
  qdrant-data:
  postgres-data:

networks:
  ai-agent-network:
    driver: bridge
